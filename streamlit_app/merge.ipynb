{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f82ab212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VERIFICACI√ìN COLUMNA 'Post' ===\n",
      "DataFrame 1 tiene columna 'Post': True\n",
      "DataFrame 2 tiene columna 'Post': True\n",
      "\n",
      "DataFrame 1 - Columna 'Post':\n",
      "  Tipo: object\n",
      "  Valores √∫nicos: 176\n",
      "  Primeros valores: ['?? ¬°La serie de tu vida comienza en la CUN!  ?? Con CT AYUDA, solo necesitas el 10% de la matr√≠cula inicial. ¬°Nosotros financiamos el resto!', '?? ¬°La serie de tu vida comienza en la CUN!  ?? Con CT AYUDA, solo necesitas el 10% de la matr√≠cula inicial. ¬°Nosotros financiamos el resto!', '?? ¬°La serie de tu vida comienza en la CUN!  ?? Con CT AYUDA, solo necesitas el 10% de la matr√≠cula inicial. ¬°Nosotros financiamos el resto!', '?? ¬°La serie de tu vida comienza en la CUN!  ?? Con CT AYUDA, solo necesitas el 10% de la matr√≠cula inicial. ¬°Nosotros financiamos el resto!', '?? ¬øY para ti, qu√© canci√≥n representa ese momento tan especial? ????  #grados #grado #sue√±osymetas']\n",
      "  ¬øTiene nulos?: 0\n",
      "  Muestra de valores:\n",
      "0    ?? ¬°La serie de tu vida comienza en la CUN!  ?...\n",
      "1    ?? ¬°La serie de tu vida comienza en la CUN!  ?...\n",
      "2    ?? ¬°La serie de tu vida comienza en la CUN!  ?...\n",
      "3    ?? ¬°La serie de tu vida comienza en la CUN!  ?...\n",
      "4    ?? ¬øY para ti, qu√© canci√≥n representa ese mome...\n",
      "5    ?? ¬øY para ti, qu√© canci√≥n representa ese mome...\n",
      "6    #ComunidadAlumni | ¬°Egresado IBERO, es momento...\n",
      "7    ?? ?? #EsTuTurno | En septiembre, m√°s de 1,900...\n",
      "8    ???????? ?????????????????? ?????????? |?? ¬°??...\n",
      "9    ???????? ?????????????????? ?????????? |?? ¬°??...\n",
      "Name: Post, dtype: object\n",
      "\n",
      "DataFrame 2 - Columna 'Post':\n",
      "  Tipo: object\n",
      "  Valores √∫nicos: 177\n",
      "  Primeros valores: ['#?????????????????? | ?? ¬øPor qu√© estudiar Administraci√≥n de Empresas en IBERO? Descubre todo tu potencial con nuestro programa.', '#ComunidadAlumni | ¬°Egresado IBERO, es momento de volvernos a encontrar! ?? Te invitamos a ser parte del ???? ???????????????? ???????????????? ???? ??????????????????. Una jornada perfecta para reconectar con tus compa√±eros, fortalecer la red de egresad', '#EnModoAcreditados ?? |?¬°???? ????????????????, ?????????????????? ??????????!? Hoy celebramos juntos un logro que refleja el esfuerzo, la dedicaci√≥n y el amor por la educaci√≥n de calidad. Con enorme orgullo y alegr√≠a, les contamos que hemos obtenido la ??????????????????????¬¥?? ?????????????????????????? ???? ???????? ?????????????? otorgada por el ???????????????????? ???? ????????????????¬¥?? ????????????????, un reconocimiento que valida el compromiso de la IBERO, de Planeta Formaci√≥n y Universidades, con la excelencia educativa.?', '#EnVideo??? ??Comunidad Areandina: en este video te contamos las alternativas que tienes de movilizaci√≥n debido al cierre de la estaci√≥n de Transmilenio Calle 72??', '#EsTuTurno | ???? En ??????????, nuestro programa de ????????????????√≠?? presencial te prepara para los desaf√≠os modernos con formaci√≥n integral y competencias digitales. ????']\n",
      "  ¬øTiene nulos?: 0\n",
      "  Muestra de valores:\n",
      "0    #?????????????????? | ?? ¬øPor qu√© estudiar Adm...\n",
      "1    #ComunidadAlumni | ¬°Egresado IBERO, es momento...\n",
      "2    #EnModoAcreditados ?? |?¬°???? ????????????????...\n",
      "3    #EnVideo??? ??Comunidad Areandina: en este vid...\n",
      "4    #EsTuTurno | ???? En ??????????, nuestro progr...\n",
      "5    #gracias porfes por tanto. ?? #emocion #emotiv...\n",
      "6    #InternacionalizacionIBERO | ¬°El mundo est√° ll...\n",
      "7    #MakingOff de nuestra pieza audiovisual para e...\n",
      "8    #PlanReferidosIBERO | Act√≠vate con el ????????...\n",
      "9    #PoliTank I Aqu√≠ est√° el consejo de una de las...\n",
      "Name: Post, dtype: object\n",
      "\n",
      "=== TODAS LAS COLUMNAS ===\n",
      "DataFrame 1: ['Post']\n",
      "DataFrame 2: ['Post', 'Categor√≠a', 'Subcategor√≠a', 'Trigger', 'Unnamed: 4']\n",
      "\n",
      "=== FORMAS ===\n",
      "DataFrame 1: (3736, 1) (filas, columnas)\n",
      "DataFrame 2: (177, 5) (filas, columnas)\n",
      "\n",
      "=== VALORES COMUNES EN 'Post' ===\n",
      "N√∫mero de valores comunes: 108\n",
      "Algunos valores comunes: ['? ¬øSab√≠as que la ic√≥nica frase \"Dios m√≠o, en tus manos colocamos este d√≠a que ya pas√≥ y la noche que llega\" tiene un creador?', 'Parte 1 | Preguntas de cultura general con estudiantes de la CUN. #preguntas #culturageneral #bogota', '#EnModoAcreditados ?? |?¬°???? ????????????????, ?????????????????? ??????????!? Hoy celebramos juntos un logro que refleja el esfuerzo, la dedicaci√≥n y el amor por la educaci√≥n de calidad. Con enorme orgullo y alegr√≠a, les contamos que hemos obtenido la ??????????????????????¬¥?? ?????????????????????????? ???? ???????? ?????????????? otorgada por el ???????????????????? ???? ????????????????¬¥?? ????????????????, un reconocimiento que valida el compromiso de la IBERO, de Planeta Formaci√≥n y Universidades, con la excelencia educativa.?', '¬°Felicidades, graduados! ?? ¬°√âxito y felicidad en su nuevo camino!????#gradoscun #gradosuniversitarios #graduaci√≥n', '¬°Transforma tu futuro en Areandina! ? homologa tu titulo SENA y avanza hacia el √©xito.']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los dataframes\n",
    "df1_path = r\"C:\\Users\\juan_garnicac\\Documents\\post\\Definici√≥n_Categorias_TikTok.xlsx\"\n",
    "df2_path = r\"C:\\Users\\juan_garnicac\\Downloads\\soloComentariosUnicosTikTok.xlsx\"\n",
    "\n",
    "df1 = pd.read_excel(df1_path, sheet_name='Trabajo14Octubre')\n",
    "df2 = pd.read_excel(df2_path, sheet_name='Hoja1')\n",
    "\n",
    "# Verificar si tienen columna \"Post\" (con may√∫scula)\n",
    "print(\"=== VERIFICACI√ìN COLUMNA 'Post' ===\")\n",
    "print(f\"DataFrame 1 tiene columna 'Post': {'Post' in df1.columns}\")\n",
    "print(f\"DataFrame 2 tiene columna 'Post': {'Post' in df2.columns}\")\n",
    "\n",
    "# Si existen, mostrar informaci√≥n espec√≠fica de esas columnas\n",
    "if 'Post' in df1.columns:\n",
    "    print(f\"\\nDataFrame 1 - Columna 'Post':\")\n",
    "    print(f\"  Tipo: {df1['Post'].dtype}\")\n",
    "    print(f\"  Valores √∫nicos: {df1['Post'].nunique()}\")\n",
    "    print(f\"  Primeros valores: {df1['Post'].head().tolist()}\")\n",
    "    print(f\"  ¬øTiene nulos?: {df1['Post'].isnull().sum()}\")\n",
    "    print(f\"  Muestra de valores:\")\n",
    "    print(df1['Post'].head(10))\n",
    "\n",
    "if 'Post' in df2.columns:\n",
    "    print(f\"\\nDataFrame 2 - Columna 'Post':\")\n",
    "    print(f\"  Tipo: {df2['Post'].dtype}\")\n",
    "    print(f\"  Valores √∫nicos: {df2['Post'].nunique()}\")\n",
    "    print(f\"  Primeros valores: {df2['Post'].head().tolist()}\")\n",
    "    print(f\"  ¬øTiene nulos?: {df2['Post'].isnull().sum()}\")\n",
    "    print(f\"  Muestra de valores:\")\n",
    "    print(df2['Post'].head(10))\n",
    "\n",
    "# Mostrar todas las columnas para referencia\n",
    "print(f\"\\n=== TODAS LAS COLUMNAS ===\")\n",
    "print(f\"DataFrame 1: {df1.columns.tolist()}\")\n",
    "print(f\"DataFrame 2: {df2.columns.tolist()}\")\n",
    "\n",
    "# Mostrar formas de los dataframes\n",
    "print(f\"\\n=== FORMAS ===\")\n",
    "print(f\"DataFrame 1: {df1.shape} (filas, columnas)\")\n",
    "print(f\"DataFrame 2: {df2.shape} (filas, columnas)\")\n",
    "\n",
    "# Verificar si hay valores comunes en la columna Post\n",
    "if 'Post' in df1.columns and 'Post' in df2.columns:\n",
    "    post_common = set(df1['Post'].dropna()) & set(df2['Post'].dropna())\n",
    "    print(f\"\\n=== VALORES COMUNES EN 'Post' ===\")\n",
    "    print(f\"N√∫mero de valores comunes: {len(post_common)}\")\n",
    "    if len(post_common) > 0:\n",
    "        print(f\"Algunos valores comunes: {list(post_common)[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87b59f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizando textos...\n",
      "Coincidencias encontradas despu√©s de normalizar: 175\n",
      "\n",
      "Algunas coincidencias normalizadas:\n",
      "1. cumple tus metas academicas con credipoli ya no hay obstaculos para alcanzar tu sueno de estudiar en...\n",
      "2. areandina es tu mejor opcion matriculate ya aprovecha los descuentos y las multiples opciones de fin...\n",
      "3. la serie de tu vida comienza en la cun con ct ayuda solo necesitas el 10 de la matricula inicial nos...\n",
      "\n",
      "=== ARCHIVO GUARDADO EXITOSAMENTE ===\n",
      "üìä DataFrame principal (df1): (3736, 2)\n",
      "üìä DataFrame secundario (df2): (177, 6)\n",
      "‚úÖ DataFrame mergeado: (3736, 5)\n",
      "üéØ Coincidencias encontradas: 175 posts √∫nicos\n",
      "üìà Filas con categor√≠as asignadas: 3732 de 3736 (99.89%)\n",
      "üíæ Archivo guardado en: C:\\Users\\juan_garnicac\\Documents\\post\\mergTiktoK.xlsx\n",
      "\n",
      "=== DISTRIBUCI√ìN POR CATEGOR√çAS ===\n",
      "+----+---------------------------------------+------------+\n",
      "|    | Categor√≠a                             |   Cantidad |\n",
      "+====+=======================================+============+\n",
      "|  0 | Entretenimiento / Cultura / Lifestyle |       1390 |\n",
      "+----+---------------------------------------+------------+\n",
      "|  1 | Inspiracional / Emocional             |       1125 |\n",
      "+----+---------------------------------------+------------+\n",
      "|  2 | Promocional / Comercial               |        421 |\n",
      "+----+---------------------------------------+------------+\n",
      "|  3 | Institucional / Marca                 |        365 |\n",
      "+----+---------------------------------------+------------+\n",
      "|  4 | Comunidad / Participaci√≥n             |        321 |\n",
      "+----+---------------------------------------+------------+\n",
      "|  5 | Informativo / Educativo               |         63 |\n",
      "+----+---------------------------------------+------------+\n",
      "|  6 | Responsabilidad / Impacto Social      |         47 |\n",
      "+----+---------------------------------------+------------+\n",
      "\n",
      "=== EJEMPLOS DE RESULTADOS ===\n",
      "\n",
      "üß© Filas CON categor√≠as asignadas:\n",
      "+----------------------------------------------------+-------------------------+-------------------------------+-------------------------------------------------+--------------+\n",
      "| Post                                               | Categor√≠a               | Subcategor√≠a                  | Trigger                                         |   Unnamed: 4 |\n",
      "+====================================================+=========================+===============================+=================================================+==============+\n",
      "| ?? ¬°La serie de tu vida comienza en la CUN!  ??    | Promocional / Comercial | Becas, beneficios, descuentos | \"solo necesitas el 10%\", \"financiamos el resto\" |          nan |\n",
      "| Con CT AYUDA, solo necesitas el 10% de la          |                         |                               |                                                 |              |\n",
      "| matr√≠cula inicial. ¬°Nosotros financiamos el resto! |                         |                               |                                                 |              |\n",
      "+----------------------------------------------------+-------------------------+-------------------------------+-------------------------------------------------+--------------+\n",
      "| ?? ¬°La serie de tu vida comienza en la CUN!  ??    | Promocional / Comercial | Becas, beneficios, descuentos | \"solo necesitas el 10%\", \"financiamos el resto\" |          nan |\n",
      "| Con CT AYUDA, solo necesitas el 10% de la          |                         |                               |                                                 |              |\n",
      "| matr√≠cula inicial. ¬°Nosotros financiamos el resto! |                         |                               |                                                 |              |\n",
      "+----------------------------------------------------+-------------------------+-------------------------------+-------------------------------------------------+--------------+\n",
      "\n",
      "‚úÖ Verificaci√≥n: Archivo creado exitosamente\n",
      "üìè Tama√±o del archivo: 77.69 KB\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tabulate as tb\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# Cargar los dataframes\n",
    "df1_path = r\"C:\\Users\\juan_garnicac\\Documents\\post\\Definici√≥n_Categorias_TikTok.xlsx\"\n",
    "df2_path = r\"C:\\Users\\juan_garnicac\\Downloads\\soloComentariosUnicosTikTok.xlsx\"\n",
    "\n",
    "df1 = pd.read_excel(df1_path, sheet_name='Trabajo14Octubre')\n",
    "df2 = pd.read_excel(df2_path, sheet_name='Hoja1')\n",
    "\n",
    "# Funci√≥n para normalizar texto completamente\n",
    "def normalizar_texto(texto):\n",
    "    if pd.isna(texto):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convertir a string y min√∫sculas\n",
    "    texto = str(texto).lower().strip()\n",
    "    \n",
    "    # Eliminar tildes y caracteres especiales\n",
    "    texto = unicodedata.normalize('NFKD', texto).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    \n",
    "    # Eliminar signos de puntuaci√≥n y caracteres especiales\n",
    "    texto = re.sub(r'[^\\w\\s]', '', texto)\n",
    "    \n",
    "    # Reemplazar m√∫ltiples espacios por uno solo\n",
    "    texto = re.sub(r'\\s+', ' ', texto)\n",
    "    \n",
    "    return texto.strip()\n",
    "\n",
    "# Aplicar normalizaci√≥n a la columna Post en ambos dataframes\n",
    "print(\"Normalizando textos...\")\n",
    "df1['Post_normalizado'] = df1['Post'].apply(normalizar_texto)\n",
    "df2['Post_normalizado'] = df2['Post'].apply(normalizar_texto)\n",
    "\n",
    "# Verificar coincidencias despu√©s de la normalizaci√≥n\n",
    "coincidencias = set(df1['Post_normalizado']) & set(df2['Post_normalizado'])\n",
    "print(f\"Coincidencias encontradas despu√©s de normalizar: {len(coincidencias)}\")\n",
    "\n",
    "# Mostrar algunas coincidencias normalizadas\n",
    "if len(coincidencias) > 0:\n",
    "    print(\"\\nAlgunas coincidencias normalizadas:\")\n",
    "    for i, post in enumerate(list(coincidencias)[:3]):\n",
    "        print(f\"{i+1}. {post[:100]}...\")\n",
    "\n",
    "# Seleccionar las columnas de df2 que queremos llevar al merge\n",
    "columnas_df2 = ['Post_normalizado', 'Categor√≠a', 'Subcategor√≠a', 'Trigger', 'Unnamed: 4']\n",
    "\n",
    "# Hacer el merge con los textos normalizados\n",
    "merged_df = pd.merge(df1, df2[columnas_df2], on='Post_normalizado', how='left')\n",
    "\n",
    "# Eliminar la columna normalizada del resultado final\n",
    "merged_df = merged_df.drop('Post_normalizado', axis=1)\n",
    "\n",
    "# Ruta para guardar el archivo\n",
    "output_path = r\"C:\\Users\\juan_garnicac\\Documents\\post\\mergTiktoK.xlsx\"\n",
    "\n",
    "# Guardar el DataFrame mergeado en Excel\n",
    "merged_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(\"\\n=== ARCHIVO GUARDADO EXITOSAMENTE ===\")\n",
    "print(f\"üìä DataFrame principal (df1): {df1.shape}\")\n",
    "print(f\"üìä DataFrame secundario (df2): {df2.shape}\")\n",
    "print(f\"‚úÖ DataFrame mergeado: {merged_df.shape}\")\n",
    "print(f\"üéØ Coincidencias encontradas: {len(coincidencias)} posts √∫nicos\")\n",
    "\n",
    "# Calcular filas con categor√≠as asignadas\n",
    "filas_con_categoria = merged_df[~merged_df['Categor√≠a'].isna()].shape[0]\n",
    "porcentaje = (filas_con_categoria / len(merged_df)) * 100\n",
    "print(f\"üìà Filas con categor√≠as asignadas: {filas_con_categoria} de {len(merged_df)} ({porcentaje:.2f}%)\")\n",
    "print(f\"üíæ Archivo guardado en: {output_path}\")\n",
    "\n",
    "# Mostrar resumen por categor√≠as\n",
    "if not merged_df['Categor√≠a'].isna().all():\n",
    "    print(f\"\\n=== DISTRIBUCI√ìN POR CATEGOR√çAS ===\")\n",
    "    categorias_count = merged_df['Categor√≠a'].value_counts()\n",
    "    print(tb.tabulate(categorias_count.reset_index(), \n",
    "                     headers=['Categor√≠a', 'Cantidad'], \n",
    "                     tablefmt='grid'))\n",
    "\n",
    "# Mostrar ejemplos de resultados\n",
    "print(f\"\\n=== EJEMPLOS DE RESULTADOS ===\")\n",
    "\n",
    "# Filas CON coincidencia\n",
    "if filas_con_categoria > 0:\n",
    "    print(\"\\nüß© Filas CON categor√≠as asignadas:\")\n",
    "    con_categoria = merged_df[~merged_df['Categor√≠a'].isna()].head(2)\n",
    "    print(tb.tabulate(con_categoria, headers='keys', tablefmt='grid', showindex=False, maxcolwidths=50))\n",
    "\n",
    "# Verificaci√≥n de que el archivo se guard√≥ correctamente\n",
    "import os\n",
    "if os.path.exists(output_path):\n",
    "    file_size = os.path.getsize(output_path) / 1024  # Tama√±o en KB\n",
    "    print(f\"\\n‚úÖ Verificaci√≥n: Archivo creado exitosamente\")\n",
    "    print(f\"üìè Tama√±o del archivo: {file_size:.2f} KB\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Error: El archivo no se pudo crear\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
